{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_full.csv')  # on lit le dataset train_full\n",
    "test = pd.read_csv('data/test_full.csv')    # on lit le dataset test_full\n",
    "\n",
    "print(train.shape)  # on affiche les dimensions de train\n",
    "print(test.shape)   # on affiche les dimensions de test\n",
    "\n",
    "train.columns.values   # on affiche les features de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime la colonne Id de Train et Test\n",
    "\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Exploration de la target SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remarque que la distribution de SalePrice n'est pas equilibrée\n",
    "# On va donc regarder si une transformation logarythmique peux uniformiser la distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SalePrice'] = np.log1p(train['SalePrice'])\n",
    "sns.distplot(train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effectivement, la distribution est bien mieux repartie, et donc bien plus exploitable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Séparation des données qualitatives et quantitatives du train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va creer un subset qui contient uniquement les 'object' (quali) et un subset avec uniquement les 'float' et 'int' (quanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset qualitatif\n",
    "quali = train.select_dtypes(include=['object']).columns\n",
    "print(quali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quanti\n",
    "quanti = train.select_dtypes(include=['int64','float64']).columns\n",
    "print(quanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_quanti = len(quanti)\n",
    "num_quali = len(quali)\n",
    "\n",
    "print((num_quali), \"features qualitatives\")\n",
    "print((num_quanti), \"features quantitatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyses des features quantitatives avec le heatmap\n",
    "\n",
    "corrmat = train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True, linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[quanti]\n",
    "correlation = dict()\n",
    "\n",
    "for x in train[quanti]:\n",
    "    correlation[x] = round(train[x].corr(train['SalePrice']),2)\n",
    "    \n",
    "for key in sorted(corr_output,key = corr_output.get, reverse=True):\n",
    "    if corr_output[key] >= 0.5:\n",
    "            print(key, corr_output[key])  \n",
    "            \n",
    "\n",
    "# corr_mat de ces 10 features\n",
    "\n",
    "k = 11\n",
    "cols = corrmat.nlargest(k,'SalePrice').index\n",
    "cols \n",
    "\n",
    "corr_mat_10 = train[cols].corr()\n",
    "corr_mat_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse features numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train[quanti]:\n",
    "    sns.regplot(x=feature,y='SalePrice', data=train)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimination des outliers LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='LotFrontage',y='SalePrice', data=train)\n",
    "print(f\"corr : {round(train['LotFrontage'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[(train['LotFrontage']>300)].index).reset_index(drop=True)\n",
    "sns.regplot(x='LotFrontage',y='SalePrice', data=train)\n",
    "print(f\"corr : {round(train['LotFrontage'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimination des outliers LotArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='LotArea',y='SalePrice', data=train)\n",
    "print(f\"corr : {round(train['LotArea'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[(train['LotArea']>60000)].index).reset_index(drop=True)\n",
    "sns.regplot(x='LotArea',y='SalePrice', data=train)\n",
    "print(f\"corr : {round(train['LotArea'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimination des outliers GarageArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='GarageArea',y='SalePrice', data=train)\n",
    "print(f\"corr : {round(train['GarageArea'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[(train['GarageArea']>1100)].index).reset_index(drop=True)\n",
    "sns.regplot(x='GarageArea',y='SalePrice', data=train)\n",
    "print(f\"corr : {round(train['GarageArea'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimination des outliers GarageCars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='GarageCars',y='SalePrice', data=train)\n",
    "print(f\"corr : {round(train['GarageCars'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etant donné qu'il s'agit d'un feature quantitatif mais d'apparance qualitatif, on essaye une visualisation avec des Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=train['GarageCars'], y=train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[(train['GarageCars']>3) & (train['SalePrice']<13)].index).reset_index(drop=True)\n",
    "print(f\"corr : {round(train['GarageCars'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimination des outliers WoodDeckSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='WoodDeckSF',y='SalePrice', data=train)\n",
    "print(f\"corr : {round(train['WoodDeckSF'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[(train['WoodDeckSF']>600)].index).reset_index(drop=True)\n",
    "print(f\"corr : {round(train['WoodDeckSF'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimination des outliers OpenPorchSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='OpenPorchSF',y='SalePrice', data=train)\n",
    "print(f\"corr : {round(train['OpenPorchSF'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[(train['OpenPorchSF']>500) & (train['SalePrice']<11)].index).reset_index(drop=True)\n",
    "print(f\"corr : {round(train['OpenPorchSF'].corr(train['SalePrice']),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(f\"Supression de {1460-1431} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des valeurs manquantes dans le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On combine les deux dataset pour faire les modifs en une seule fois\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "print(ntrain)\n",
    "ntest = test.shape[0]\n",
    "y_train = train.SalePrice.values\n",
    "y_train.to_csv('data/y_train.csv')\n",
    "print(y_train)\n",
    "datas = pd.concat((train, test)).reset_index(drop=True)\n",
    "datas.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(datas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### %Valeurs manquantes dans le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percnan = round((datas.isnull().sum() / len(datas)) * 100,2)  # toutes les features et leurs nombres de zéros ( % )\n",
    "percnan = percnan[percnan > 0] # On enleve celles qui n'ont pas de valeurs nulles \n",
    "percnan = percnan.sort_values(ascending=False)\n",
    "missing_values = pd.DataFrame({'Missing Ratio': percnan})\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple pour voir le nombre de NA par features et la distribution des valeurs\n",
    "print(datas['MSZoning'].isnull().sum())\n",
    "print(datas['MSZoning'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas[\"PoolQC\"] = datas[\"PoolQC\"].fillna(\"None\")\n",
    "datas[\"MiscFeature\"] = datas[\"MiscFeature\"].fillna(\"None\")\n",
    "datas[\"Alley\"] = datas[\"Alley\"].fillna(\"None\")\n",
    "datas[\"Fence\"] = datas[\"Fence\"].fillna(\"None\")\n",
    "datas[\"FireplaceQu\"] = datas[\"FireplaceQu\"].fillna(\"None\")\n",
    "datas[\"LotFrontage\"] = datas.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    datas[col] = datas[col].fillna('None')\n",
    "    \n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    datas[col] = datas[col].fillna(0)\n",
    "    \n",
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    datas[col] = datas[col].fillna(0)\n",
    "    \n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    datas[col] = datas[col].fillna('None')\n",
    "    \n",
    "datas[\"MasVnrType\"] = datas[\"MasVnrType\"].fillna(\"None\")\n",
    "datas[\"MasVnrArea\"] = datas[\"MasVnrArea\"].fillna(0)\n",
    "datas['MSZoning'] = datas.groupby(\"Neighborhood\")['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "datas[\"Functional\"] = datas[\"Functional\"].fillna(\"Typ\")\n",
    "datas['Electrical'] = datas['Electrical'].fillna(datas['Electrical'].mode()[0])\n",
    "datas['KitchenQual'] = datas['KitchenQual'].fillna(datas['KitchenQual'].mode()[0])\n",
    "datas['Exterior1st'] = datas['Exterior1st'].fillna(datas['Exterior1st'].mode()[0])\n",
    "datas['Exterior2nd'] = datas['Exterior2nd'].fillna(datas['Exterior2nd'].mode()[0])\n",
    "datas['SaleType'] = datas['SaleType'].fillna(datas['SaleType'].mode()[0])\n",
    "datas['MSSubClass'] = datas['MSSubClass'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas = datas.drop(['Utilities'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On verifie qu'il n'y ai plus de Na dans le dataset\n",
    "\n",
    "percnan = round((datas.isnull().sum() / len(datas)) * 100,2)  # toutes les features et leurs nombres de zéros ( % )\n",
    "percnan = percnan[percnan > 0] # On enleve celles qui n'ont pas de valeurs nulles \n",
    "percnan = percnan.sort_values(ascending=False)\n",
    "missing_values = pd.DataFrame({'Missing Ratio': percnan})\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modification des features contenant des valeurs String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation des valeurs string \"hierarchisables\"\n",
    "# on utilise .map pour cette etape\n",
    "\n",
    "datas.Alley = datas.Alley.map({'None':0, 'Grvl':1, 'Pave':2})\n",
    "datas.BsmtCond =  datas.BsmtCond.map({'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "datas.BsmtExposure = datas.BsmtExposure.map({'None':0, 'No':1, 'Mn':2, 'Av':3, 'Gd':4})\n",
    "datas['BsmtFinType1'] = datas['BsmtFinType1'].map({'None':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6})\n",
    "datas['BsmtFinType2'] = datas['BsmtFinType2'].map({'None':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6})\n",
    "datas.BsmtQual = datas.BsmtQual.map({'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "datas.ExterCond = datas.ExterCond.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "datas.ExterQual = datas.ExterQual.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "datas.FireplaceQu = datas.FireplaceQu.map({'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "datas.Functional = datas.Functional.map({'Sal':1, 'Sev':2, 'Maj2':3, 'Maj1':4, 'Mod':5, 'Min2':6, 'Min1':7, 'Typ':8})\n",
    "datas.GarageCond = datas.GarageCond.map({'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "datas.GarageQual = datas.GarageQual.map({'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "datas.HeatingQC = datas.HeatingQC.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "datas.KitchenQual = datas.KitchenQual.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "datas.LandSlope = datas.LandSlope.map({'Sev':1, 'Mod':2, 'Gtl':3}) \n",
    "datas.PavedDrive = datas.PavedDrive.map({'N':1, 'P':2, 'Y':3})\n",
    "datas.PoolQC = datas.PoolQC.map({'None':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "datas.Street = datas.Street.map({'Grvl':1, 'Pave':2})\n",
    "datas.Fence = datas.Fence.map(({'None':0 ,'MnWw':1 ,'GdWo':2, 'MnPrv':3}))\n",
    "datas.GarageFinish = datas.GarageFinish.map(({'None':0 ,'Unf':1 ,'RFn':2, 'Fin':3}))\n",
    "datas.LotShape = datas.LotShape.map(({'IR3':0 ,'IR3':1 ,'IR1':2, 'Reg':3}))\n",
    "datas.CentralAir = datas.CentralAir.map(({'N':0 ,'Y':1}))\n",
    "datas.MSSubClass = datas.MSSubClass.map({20:'class1', 30:'class2', 40:'class3', 45:'class4',\n",
    "                                   50:'class5', 60:'class6', 70:'class7', 75:'class8',\n",
    "                                   80:'class9', 85:'class10', 90:'class11', 120:'class12',\n",
    "                                   150:'class13', 160:'class14', 180:'class15', 190:'class16'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_quan_data = len(datas.select_dtypes(include=['int64','float64']).columns)\n",
    "num_qual_data = len(datas.select_dtypes(include=['object']).columns)\n",
    "\n",
    "print(f\"{num_quan_data} features quantitatives & {num_qual_data} features qualitatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quali\n",
    "qual_data = datas.select_dtypes(include=['object']).columns\n",
    "print(qual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacement des valeurs Quali restantes avec la fonction Dummies \n",
    "\n",
    "dummy_drop=[]\n",
    "for i in qual_data:\n",
    "    dummy_drop += [i+'_'+str(datas[i].unique()[-1])] # Rajoute dans une liste la derniere valeur de chaque features ex:\n",
    "    # Sexe : Homme ou Femme , va rajouter dans dummy_drop Femme\n",
    "    \n",
    "# create dummy variables\n",
    "datas = pd.get_dummies(datas,columns=qual_data) \n",
    "# drop the last column generated from each categorical feature\n",
    "datas = datas.drop(dummy_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datas[:ntrain]\n",
    "test = datas[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "(1444, 80)\n",
    "(1459, 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"data/trainprep.csv\")\n",
    "test.to_csv(\"data/testprep.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
